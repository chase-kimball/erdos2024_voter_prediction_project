{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f65dcda-0453-41da-9bc7-a6ad3db37bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely import centroid\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0215536-160f-429e-ab10-66d1d2f57068",
   "metadata": {},
   "source": [
    "# Convert death simplex data to Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cedade-4dcc-40f8-8fb9-a77a20c36236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_simplicies_to_df(data):\n",
    "\n",
    "    keys = ['lon1','lat1','lon2','lat2','lon3','lat3','lon_center','lat_center',\n",
    "            'death_filtration_value','death_filtration_zscore','death_birth_ratio']\n",
    "    \n",
    "    pdict = dict(zip(keys,[[] for key in keys]))\n",
    "    \n",
    "    for d in data:\n",
    "        coords = d[0].__geo_interface__['coordinates'][0]\n",
    "\n",
    "        #get coordinates of centroid, probably useful\n",
    "        lonc, latc = centroid(d[0]).__geo_interface__['coordinates']\n",
    "\n",
    "        # make sure the last coordinate pair is redundant and we can throw it away\n",
    "        assert coords[-1] == coords[0]\n",
    "    \n",
    "        lon1, lat1= coords[0]\n",
    "        lon2, lat2 = coords[1]\n",
    "        lon3, lat3 = coords[2]\n",
    "\n",
    "        # get death filtration values, zscores, and death/birth ratio\n",
    "        dfv, dfz, dbr = d[1:]\n",
    "\n",
    "        row = [lon1, lat1, lon2, lat2, lon3, lat3, lonc, latc, dfv, dfz, dbr]\n",
    "        for ii, key in enumerate(keys):\n",
    "            pdict[key].append(row[ii])\n",
    "\n",
    "    return pd.DataFrame(pdict)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c427f95a-bfb1-4585-b551-666691894c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slc Folder already exists. Continuing\n",
      "chc Folder already exists. Continuing\n",
      "atl Folder already exists. Continuing\n",
      "jax Folder already exists. Continuing\n",
      "nyc Folder already exists. Continuing\n"
     ]
    }
   ],
   "source": [
    "paths = ['../Salt Lake City/slc_death_simplices_by_death_in_dim_1.npy',\n",
    "         '../Chicago/chc_death_simplices_by_death_in_dim_1.npy',\n",
    "         '../Atlanta/atl_death_simplices_by_death_in_dim_1.npy',\n",
    "         '../Jacksonville/jax_death_simplices_by_death_in_dim_1.npy',\n",
    "         '../NYC/nyc_death_simplices_by_death_in_dim_1.npy'\n",
    "        ]\n",
    "for path in paths:\n",
    "    folder_name = path.split('/')[2].split('_')[0]\n",
    "    file_name = '{}.csv'.format(path.split('/')[2].split('.')[0])\n",
    "\n",
    "    try: os.mkdir('../project_data/{}'.format(folder_name))\n",
    "    except FileExistsError: print('{} Folder already exists. Continuing'. format(folder_name))\n",
    "    shutil.copy(path, '../project_data/{}'.format(folder_name))\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "\n",
    "    df = convert_simplicies_to_df(data)\n",
    "\n",
    "    df.to_csv('../project_data/{}/{}'.format(folder_name,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047d0a5-4c10-4437-8fcd-715e7210b4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
